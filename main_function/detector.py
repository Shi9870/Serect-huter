import xgboost as xgb
import numpy as np
import os
import re
import sys

# ç¢ºä¿å¯ä»¥ import core.utils
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from utils import extract_features

class MLDetector:
    def __init__(self):
        self.string_pattern = re.compile(r'["\'](.*?)["\']')
        self.model = None


        
        # --- Debug: å°å‡ºç›®å‰ detector.py çš„ä½ç½® ---
        current_dir = os.path.dirname(os.path.abspath(__file__))
        print(f"[DEBUG] detector.py ä½æ–¼: {current_dir}")

        # é‡æ–°çµ„è£è·¯å¾‘ (å‡è¨­ ml è³‡æ–™å¤¾åœ¨ä¸Šä¸€å±¤)
        model_path = os.path.join(current_dir, '..', 'ml', 'xgb_model.json')
        # è½‰æˆçµ•å°è·¯å¾‘ï¼Œæ–¹ä¾¿é™¤éŒ¯
        model_path = os.path.abspath(model_path) 
        
        print(f"[DEBUG] æ­£åœ¨å˜—è©¦è¼‰å…¥æ¨¡å‹: {model_path}") # ğŸ”¥ é—œéµ Debug

        if os.path.exists(model_path):
            try:
                self.model = xgb.Booster()
                self.model.load_model(model_path)
                print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
            except Exception as e:
                print(f"âŒ æ¨¡å‹è¼‰å…¥ç™¼ç”ŸéŒ¯èª¤: {e}")
                self.model = None
        else:
            print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼è«‹ç¢ºèªè·¯å¾‘æ˜¯å¦æ­£ç¢º")

    def scan_line(self, line_content, line_num):
        """
        æƒæå–®è¡Œå…§å®¹ä¸¦é€²è¡Œ AI é æ¸¬ (å·²ä¿®æ­£ç‰¹å¾µåç¨±å•é¡Œ)
        """
        potential_strings = self.string_pattern.findall(line_content)
        results = []
        
        # å¦‚æœé€™è¡Œæœ‰å…§å®¹ï¼Œå°å‡ºä¾†ç¢ºèªæœ‰è®€åˆ° (é™¤éŒ¯ç”¨ï¼Œä¹‹å¾Œå¯ä»¥è¨»è§£æ‰)
        # if len(line_content.strip()) > 0:
        #     print(f"[DEBUG-RAW] Line {line_num} å…§å®¹: {line_content.strip()}")

        for text in potential_strings:
            # 1. éæ¿¾çŸ­å­—ä¸² (å¤ªçŸ­ä¸å¯èƒ½æ˜¯ Key)
            if len(text) < 8 or len(text) > 200:
                # print(f"[DEBUG] Ignored (Length mismatch): '{text}'") 
                continue
            
            # 2. åªæœ‰åœ¨æ¨¡å‹å­˜åœ¨æ™‚æ‰é æ¸¬
            if self.model:
                try:
                    # æå–ç‰¹å¾µ
                    features = np.array([extract_features(text)])
                    
                    # å»ºç«‹ XGBoost å°ˆç”¨çš„ DMatrix
                    dtest = xgb.DMatrix(features)
                    
                    # ğŸ”¥ [é—œéµä¿®æ­£] æ‰‹å‹•è£œä¸Šç‰¹å¾µåç¨± (å¿…é ˆè·Ÿè¨“ç·´æ™‚å®Œå…¨ä¸€æ¨£ï¼)

                    dtest.feature_names = ['Entropy', 'Length', 'Digit Ratio', 'Upper Ratio', 'Symbol Ratio', 'Prefix Score', 'Length Score']
                    
                    # é€²è¡Œé æ¸¬
                    prob = self.model.predict(dtest)[0]
                    
                    # å°å‡ºè©•åˆ†çµæœ (é€™è¡Œæœƒè®“ä½ çŸ¥é“å®ƒæ´»è‘—ï¼)
                    print(f"[DEBUG] Analyze: '{text}' => Score: {prob:.4f}")

                    # 3. åˆ¤æ–·é¢¨éšª
                    # Defined thresholds based on empirical distribution where max scores are ~0.7
                    # Logic updated to capture lower-confidence signals as "Low" rather than ignoring them
                    THRESHOLDS = {
                        "Critical": 0.65, # Empirical peak for highest confidence matches
                        "High": 0.45,     # Strong structural match
                        "Medium": 0.25,   # Partial match or lower entropy signal
                        "Low": 0.10       # Weak signal (noise floor), useful for audit logs
                    }

                    risk_level = None

                    if prob > 0.15:
                        if prob > 0.65:
                            risk = "CRITICAL" # Reserved for highest confidence (e.g., standard AWS patterns)
                        elif prob > 0.45:
                            risk = "HIGH"     # Strong structural match, likely valid
                        elif prob > 0.35:
                            risk = "MEDIUM"   # Uncertain zone; structurally plausible but low confidence
                        else:
                            risk = "LOW"      # (0.15-0.35) Reclassified fakes/unknown tokens to reduce alert fatigue
                    
                        results.append({
                            "line": line_num,
                            "word": text,
                            "score": round(prob * 100, 1),
                            "risk": risk
                        })
                except Exception as e:
                    print(f"âŒ é æ¸¬æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            else:
                # å¦‚æœæ²’æœ‰æ¨¡å‹ï¼Œå°å‡ºè­¦å‘Š
                print(f"[CRITICAL] ç™¼ç¾æ½›åœ¨ç›®æ¨™ '{text}'ï¼Œä½† AI æ¨¡å‹æœªè¼‰å…¥ï¼Œç„¡æ³•åˆ†æï¼")
        
        return results